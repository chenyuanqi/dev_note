
### 锁机制
数据库锁设计的初衷是处理并发问题。  

根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类。  
**全局锁**  
全局锁就是对整个数据库实例加锁。  
MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。  

全局锁的典型使用场景是，做全库逻辑备份，也就是把整库每个表都 select 出来存成文本。  
全局锁，在备份过程中整个库完全处于只读状态，如果在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。但是，如果不加锁的话，备份系统备份得到的库不是一个逻辑时间点，这个视图是逻辑就会不一致。然而，single-transaction 的方法只适用于所有的表使用事务引擎的库（如 InnoDB），但是 MyIsam 不支持事务就必须使用全局锁了。  
如果需要全库只读，也可以使用 set global readonly=true 的方式，但是不建议这么做：  
1、在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库，修改 global 变量的方式影响面更大；  
2、在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。  

**表级锁**  
MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。  

表锁的语法是 lock tables … read/write。与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。  
`注意：lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。`  

另一类表级的锁是 MDL（metadata lock)。MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。  
所以，在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。  
> 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查  
> 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。  

如何安全地给小表加字段呢？
我们知道，事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。  
首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。如果要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。但如果是热点表，请求频繁，不得不加字段时，kill可 能未必管用，因为新的请求马上就来了；比较理想的机制是，在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。  

**行锁**  
MySQL 的行锁是在引擎层由各个引擎自己实现的。  
并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。  

行锁就是针对数据表中行记录的锁。  
在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。  
基于两阶段锁协议，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。  

**死锁和死锁检测**  
当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。  
当出现死锁以后，有两种策略：  
> 1、直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。  
> 2、发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。  

在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。而且，超时时间设置太短的话，会出现很多误伤，比如简单的锁等待会被很快解开。  

主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的：每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。  
怎么解决由这种热点行更新导致的性能问题呢？  
> 1、头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但是，这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。  
> 2、控制并发度。比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低。在数据库客户端做并发限制，会因为客户端数量多而导致服务端的峰值依然偏高；在数据库服务端做并发限制，对于相同行的更新，在进入引擎之前排队。


